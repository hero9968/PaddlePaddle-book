

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>C-API使用流程 &mdash; PaddlePaddle  文档</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="索引"
              href="../../genindex.html"/>
        <link rel="search" title="搜索" href="../../search.html"/>
    <link rel="top" title="PaddlePaddle  文档" href="../../index.html"/>
        <link rel="up" title="C-API预测库" href="index_cn.html"/>
        <link rel="next" title="RNN模型" href="../rnn/index_cn.html"/>
        <link rel="prev" title="输入/输出数据组织" href="organization_of_the_inputs_cn.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index_cn.html" class="icon icon-home"> PaddlePaddle
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../getstarted/index_cn.html">新手入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../build_and_install/index_cn.html">安装与编译</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index_cn.html">进阶使用</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../cmd_parameter/index_cn.html">命令行参数设置</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cluster/index_cn.html">分布式训练</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index_cn.html">C-API预测库</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="compile_paddle_lib_cn.html">安装与编译C-API预测库</a></li>
<li class="toctree-l3"><a class="reference internal" href="organization_of_the_inputs_cn.html">输入/输出数据组织</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">C-API使用流程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#">使用流程</a></li>
<li class="toctree-l4"><a class="reference internal" href="#">准备预测模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#">编写预测代码</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../rnn/index_cn.html">RNN模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimization/gpu_profiling_cn.html">GPU性能调优</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index_cn.html">开发标准</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/index_cn.html">FAQ</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index_cn.html">PaddlePaddle</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index_cn.html">Docs</a> &raquo;</li>
      
          <li><a href="../index_cn.html">进阶使用</a> &raquo;</li>
      
          <li><a href="index_cn.html">C-API预测库</a> &raquo;</li>
      
    <li>C-API使用流程</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/howto/capi/workflow_of_capi_cn.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="c-api">
<span id="c-api"></span><h1>C-API使用流程<a class="headerlink" href="#c-api" title="永久链接至标题">¶</a></h1>
<p>这篇文档介绍 PaddlePaddle C-API 整体使用流程。</p>
<div class="section" id="">
<span id="id1"></span><h2>使用流程<a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>使用 C-API 的工作流程如图1所示，分为（1）准备预测模型和（2）预测程序开发两大部分。</p>
<p align="center">
<img src="https://user-images.githubusercontent.com/5842774/34658453-365f73ea-f46a-11e7-9b3f-0fd112b27bae.png" width=500><br> 图1. C-API使用流程示意图
</p><ul>
<li><p class="first">准备预测模型</p>
<ol class="simple">
<li>只将神经网络结构进行序列化。<ul>
<li>只对神经网络结构进行序列化，加载模型需同时指定：网络结构的序列化结果和模型参数存储目录。</li>
</ul>
</li>
<li>将网络结构定义和训练结束存储下来的模型参数文件（多个）合并入一个文件。<ul>
<li>神经网络模型结构和训练好的模型将被序列化合并入一个文件。</li>
<li>预测时只需加载一个文件便于发布。</li>
</ul>
</li>
</ol>
<ul class="simple">
<li><strong>注意</strong>：以上两种方式只需选择其一即可。</li>
</ul>
</li>
<li><p class="first">调用 C-API 开发预测序</p>
<ol class="simple">
<li>初始化PaddlePaddle运行环境。</li>
<li>加载预测模型。</li>
<li>创建神经网络输入，组织输入数据。</li>
<li>进行前向计算，获得计算结果。</li>
<li>清理和结束。</li>
</ol>
</li>
</ul>
</div>
<div class="section" id="">
<span id="id2"></span><h2>准备预测模型<a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>准备预测模型部分，我们以手写数字识别任务为例进行介绍。手写数字识别任务定义了一个含有<a class="reference external" href="https://github.com/PaddlePaddle/book/blob/develop/02.recognize_digits/README.cn.md#softmax回归softmax-regression">两个隐层的简单全连接网络</a>，网络接受一幅图片作为输入，将图片分类到 0 ~ 9 类别标签之一。完整代码可以查看<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference/dense">此目录</a> 中的相关脚本。</p>
<p>调用C-API开发预测程序需要一个训练好的模型，运行<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference/dense">MNIST手写数字识别目录</a>下的<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/capi/examples/model_inference/dense/mnist_v2.py">mnist_v2.py</a>脚本，在终端执行<code class="docutils literal"><span class="pre">python</span> <span class="pre">mnist_v2.py</span></code>，会使用 PaddlePaddle 内置的 <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST 数据集</a>进行训练。训练好的模型默认保存在当前运行目录下的<code class="docutils literal"><span class="pre">models</span></code>目录中。</p>
<p>下面，我们将训练结束后存储下来的模型转换成预测模型。</p>
<ol>
<li><p class="first">序列化神经网络模型配置</p>
<p>PaddlePaddle 使用 protobuf 来传输网络配置文件中定义的网络结构和相关参数，使用 C-API 进行预测时，需要将网络结构使用 protobuf 进行序列化，写入文件中。</p>
<p>调用<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/python/paddle/utils/dump_v2_config.py"><code class="docutils literal"><span class="pre">paddle.utils.dump_v2_config</span></code></a>中的<code class="docutils literal"><span class="pre">dump_v2_config</span></code>函数能够将使用 PaddlePaddle V2 API 定义的神经网络结构 dump 到指定文件中，示例代码如下：</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">paddle.utils.dump_v2_config</span> <span class="kn">import</span> <span class="n">dump_v2_config</span>
<span class="kn">from</span> <span class="nn">mnist_v2</span> <span class="kn">import</span> <span class="n">network</span>

<span class="n">predict</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">is_infer</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dump_v2_config</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="s2">&quot;trainer_config.bin&quot;</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>对<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference/dense">手写数字识别</a>这个示例，<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference/dense/mnist_v2.py"><code class="docutils literal"><span class="pre">mnist_v2.py</span></code></a>脚本集成了序列化神经网络结构的过程，可以直接运行 <code class="docutils literal"><span class="pre">python</span> <span class="pre">mnist_v2.py</span> <span class="pre">--task</span> <span class="pre">dump_config</span></code> 对神经网络结构进行序列化，结果会写入当前运行目录下的<code class="docutils literal"><span class="pre">trainer_config.bin</span></code>文件中。</p>
<p>使用这种方式，需要<strong>在运行时将神经网络的多个可学习参数放在同一个目录中</strong>，C-API可以通过分别指定序列化后的网络结构文件和参数目录来加载训练好的模型。</p>
</li>
<li><p class="first">合并模型文件(可选)</p>
<p>一些情况为了便于发布，希望能够将序列化后的神经网络结构和训练好的模型参数打包进一个文件。对于这样的需求，可以使用<code class="docutils literal"><span class="pre">paddle.utils.merge_model</span></code>中的<code class="docutils literal"><span class="pre">merge_v2_model</span></code>接口对神经网络结构和训练好的参数进行序列化，将序列化结果写入一个文件内。</p>
<p>代码示例如下：</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">paddle.utils.merge_model</span> <span class="kn">import</span> <span class="n">merge_v2_modelss</span>
<span class="kn">from</span> <span class="nn">mnist_v2</span> <span class="kn">import</span> <span class="n">network</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">is_infer</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">param_file</span> <span class="o">=</span> <span class="s2">&quot;models/params_pass_4.tar&quot;</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="s2">&quot;output.paddle.model&quot;</span>
<span class="n">merge_v2_model</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">param_file</span><span class="p">,</span> <span class="n">output_file</span><span class="p">)</span>
</pre></div>
</div>
<p>对<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference/dense">手写数字识别</a>这个示例，可直接运行 <code class="docutils literal"><span class="pre">python</span></code> <a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference/dense/merge_v2_model.py">merge_v2_model.py</a>。序列化结果会写入当前运行目录下的<code class="docutils literal"><span class="pre">output.paddle.model</span></code>文件中。使用这种方式，运行时C-API可以通过指定<code class="docutils literal"><span class="pre">output.paddle.model</span></code>文件的路径来加载预测模型。</p>
</li>
</ol>
<div class="section" id="">
<span id="id3"></span><h3>注意事项<a class="headerlink" href="#" title="永久链接至标题">¶</a></h3>
<ol class="simple">
<li>为使用C-API，在调用<code class="docutils literal"><span class="pre">dump_v2_config</span></code>序列化神经网络结构时，参数<code class="docutils literal"><span class="pre">binary</span></code>必须指定为<code class="docutils literal"><span class="pre">True</span></code>。</li>
<li><strong>预测使用的网络结构往往不同于训练</strong>，通常需要去掉网络中的：（1）类别标签层；（2）损失函数层；（3）<code class="docutils literal"><span class="pre">evaluator</span></code>等，只留下核心计算层，请注意是否需要修改网络结构。</li>
<li>预测时，可以获取网络中定义的任意多个（大于等于一个）层前向计算的结果，需要哪些层的计算结果作为输出，就将这些层加入一个Python list中，作为调用<code class="docutils literal"><span class="pre">dump_v2_config</span></code>的第一个参数。</li>
</ol>
</div>
</div>
<div class="section" id="">
<span id="id4"></span><h2>编写预测代码<a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>预测代码更多详细示例代码请参考<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/capi/examples/model_inference">C-API使用示例</a> 目录下的代码示例。这一节对图1中预测代码编写的5个步骤进行介绍和说明。</p>
<div class="section" id="step-1-paddlepaddle">
<span id="step-1-paddlepaddle"></span><h3>step 1. 初始化PaddlePaddle运行环境<a class="headerlink" href="#step-1-paddlepaddle" title="永久链接至标题">¶</a></h3>
<p>第一步需调用<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/capi/main.h#L27"><code class="docutils literal"><span class="pre">paddle_init</span></code></a> 初始化PaddlePaddle运行环境，该接口接受两个参数：参数的个数和参数列表。</p>
</div>
<div class="section" id="step2">
<span id="step2"></span><h3>step2. 加载模型<a class="headerlink" href="#step2" title="永久链接至标题">¶</a></h3>
<p>这里介绍C-API使用中的一个重要概念：Gradient Machine。</p>
<p>概念上，在 PaddlePaddle 内部，一个GradientMachine类的对象管理着一组计算层（PaddlePaddle Layers）来完成前向和反向计算，并处理与之相关的所有细节。在调用C-API预测时，只需进行前向计算而无需调用反向计算。这篇文档之后部分会使用<code class="docutils literal"><span class="pre">gradient</span> <span class="pre">machine</span></code>来特指调用PaddlePaddle C-API创建的GradientMachine类的对象。每一个 <code class="docutils literal"><span class="pre">gradient</span> <span class="pre">machine</span></code> 都会管理维护一份训练好的模型，下面是C-API提供的，两种常用的模型加载方式：</p>
<ol class="simple">
<li>调用<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/capi/gradient_machine.h#L61"><code class="docutils literal"><span class="pre">paddle_gradient_machine_load_parameter_from_disk</span></code></a>接口，从磁盘加载预测模型。这时<code class="docutils literal"><span class="pre">gradient</span> <span class="pre">machine</span></code>会独立拥有一份训练好的模型；</li>
<li>调用<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/capi/gradient_machine.h#L88"><code class="docutils literal"><span class="pre">paddle_gradient_machine_create_shared_param</span></code></a>接口，与其它<code class="docutils literal"><span class="pre">gradient</span> <span class="pre">machine</span></code>的共享已经加载的预测模型。这种情况多出现在使用多线程预测时，通过多个线程共享同一个模型来减少内存开销。可参考<a class="reference external" href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/capi/examples/model_inference/multi_thread/main.c">此示例</a>。</li>
</ol>
<ul class="simple">
<li>注意事项<ol>
<li>使用PaddlePaddle V2 API训练，模型中所有可学习参数会被存为一个压缩文件，需要手动进行解压，将它们放在同一目录中，C-API不会直接加载 V2 API 存储的压缩文件。</li>
<li>如果使用<code class="docutils literal"><span class="pre">merge</span> <span class="pre">model</span></code>方式将神经网络结构和训练好的参数序列化到一个文件，请参考此<a class="reference external" href="https://github.com/PaddlePaddle/Mobile/blob/develop/Demo/linux/paddle_image_recognizer.cpp#L59">示例</a>。</li>
<li>通过灵活使用以上两个接口，加载模型可其它多种方式，例如也可在程序运行过程中再加载另外一个模型。</li>
</ol>
</li>
</ul>
</div>
<div class="section" id="step-3">
<span id="step-3"></span><h3>step 3. 创建神经网络输入，组织输入数据<a class="headerlink" href="#step-3" title="永久链接至标题">¶</a></h3>
<p>基本使用概念：</p>
<ul class="simple">
<li>在PaddlePaddle内部，神经网络中一个计算层的输入输出被组织为一个 <code class="docutils literal"><span class="pre">Argument</span></code> 结构体，如果神经网络有多个输入或者多个输出，每一个输入/输出都会对应有自己的<code class="docutils literal"><span class="pre">Argument</span></code>。</li>
<li><code class="docutils literal"><span class="pre">Argument</span></code> 并不真正“存储”数据，而是将输入/输出数据有机地组织在一起。</li>
<li>在<code class="docutils literal"><span class="pre">Argument</span></code>内部由：1. <code class="docutils literal"><span class="pre">Matrix</span></code>（二维矩阵，存储浮点类型输入/输出）；2. <code class="docutils literal"><span class="pre">IVector</span></code>（一维数组，<strong>仅用于存储整型值</strong>，多用于自然语言处理任务）来实际存储数据。</li>
</ul>
<p>C-API支持的所有输入数据类型和他们的组织方式，请参考“输入/输出数据组织”一节。</p>
<p>这篇文档的之后部分会使用<code class="docutils literal"><span class="pre">argument</span></code>来特指PaddlePaddle C-API中神经网络的一个输入/输出，使用<code class="docutils literal"><span class="pre">paddle_matrix</span></code><strong>特指</strong><code class="docutils literal"><span class="pre">argument</span></code>中用于存储数据的<code class="docutils literal"><span class="pre">Matrix</span></code>类的对象。</p>
<p>在组织神经网络输入，获取输出时，需要思考完成以下工作：</p>
<ol class="simple">
<li>为每一个输入/输出创建<code class="docutils literal"><span class="pre">argument</span></code>；</li>
<li>为每一个<code class="docutils literal"><span class="pre">argument</span></code>创建<code class="docutils literal"><span class="pre">paddle_matrix</span></code>来存储数据；</li>
</ol>
<p>与输入不同的是，不需在使用C-API时为输出<code class="docutils literal"><span class="pre">argument</span></code>的<code class="docutils literal"><span class="pre">paddle_matrix</span></code>对象分配空间。前向计算之后PaddlePaddle内部已经分配/管理了每个计算层输出的存储空间。</p>
</div>
<div class="section" id="step-4">
<span id="step-4"></span><h3>step 4. 前向计算<a class="headerlink" href="#step-4" title="永久链接至标题">¶</a></h3>
<p>完成上述准备之后，通过调用 <a class="reference external" href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/capi/gradient_machine.h#L73"><code class="docutils literal"><span class="pre">paddle_gradient_machine_forward</span></code></a> 接口完成神经网络的前向计算。</p>
</div>
<div class="section" id="step-5">
<span id="step-5"></span><h3>step 5. 清理<a class="headerlink" href="#step-5" title="永久链接至标题">¶</a></h3>
<p>结束预测之后，对使用的中间变量和资源进行清理和释放。</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../rnn/index_cn.html" class="btn btn-neutral float-right" title="RNN模型" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="organization_of_the_inputs_cn.html" class="btn btn-neutral" title="输入/输出数据组织" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, PaddlePaddle developers.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>